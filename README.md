# ğŸ§  RAG Chat System (Nepali Constitution QA)

A **Retrieval-Augmented Generation (RAG)** system built with **Google Gemini**, **FastAPI**, **Streamlit**, and **Qdrant**.
This project enables users to ask questions related to the **Nepali Constitution**, retrieve relevant context from stored documents, and get accurate AI-generated answers.

---

## ğŸ“– Overview

This RAG system focuses on questionâ€“answering over the **Nepali Constitution**.
Documents are preprocessed, chunked, and stored with metadata in a **Qdrant vector database**.
When a user asks a question, the system retrieves the most relevant chunks and uses **Google Gemini** to generate a contextual answer.

---

## âœ¨ Features

* ğŸ” **Retrieval-Augmented Generation (RAG)** pipeline using Qdrant and Gemini.
* ğŸ§© **Chunk-based document storage** with metadata for efficient retrieval.
* ğŸ¤– **Gemini Function Calling** â€” the LLM automatically triggers the retriever tool when needed.
* ğŸ’¾ **Chat history storage** in MongoDB.
* ğŸ“‚ **Document upload** and embedding generation using `models/embedding-001`.
* âš¡ **FastAPI backend** serving the RAG API.
* ğŸ–¥ï¸ **Streamlit frontend** for an interactive chat interface.

---

## ğŸ—ï¸ Architecture

```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                       Streamlit UI                       â”‚
 â”‚  - User chat interface                                   â”‚
 â”‚  - Sends questions to backend                            â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                        FastAPI Backend                   â”‚
 â”‚  - Handles chat requests                                 â”‚
 â”‚  - Calls Gemini for reasoning + function calling          â”‚
 â”‚  - Retrieves relevant chunks via retriever function       â”‚
 â”‚  - Stores chat history in MongoDB                         â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                   Qdrant Vector Database                 â”‚
 â”‚  - Stores document embeddings and metadata               â”‚
 â”‚  - Provides top-k retrieval for queries                  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                       MongoDB                            â”‚
 â”‚  - Stores chat history and user context                  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Setup Guide (Local)

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/shisir1729/RAG_chat_system.git
cd RAG_chat_system
```

### 2ï¸âƒ£ Install dependencies

```bash
uv add <packages>
```

### 3ï¸âƒ£ Configure environment

Edit the connection details in `configuration.py`:

```python
QDRANT_URL = "your_qdrant_url"
MONGO_URI = "your_mongodb_connection_string"
```

### 4ï¸âƒ£ Start the backend

```bash
 uv run uvicorn main:app --reload
```

### 5ï¸âƒ£ Run the frontend

```bash
 uvx streamlit run streamlit_learning.py
```

Now open the Streamlit app (default: `http://localhost:8501`) and start chatting!

---

## ğŸ—‚ï¸ Folder Structure

```
RAG_chat_system/
â”œâ”€â”€ main.py                 # Core FastAPI backend
â”œâ”€â”€ configuration.py        # Qdrant and MongoDB configurations
â”œâ”€â”€ streamlit_learning.py   # Streamlit frontend
â”œâ”€â”€ pyproject.toml          # Python dependencies
â””â”€â”€ README.md               # Project documentation
```

---

## ğŸ“š How It Works

1. Documents are chunked and stored with embeddings in Qdrant.
2. When a user sends a query, Gemini uses **function calling** to invoke the `retriever_text()` function.
3. The retriever searches Qdrant for relevant chunks.
4. Gemini integrates the retrieved context to generate a precise answer.
5. Chat history is saved to MongoDB for future context.

---

## ğŸ§© Tech Stack

| Component       | Technology             |
| --------------- | ---------------------- |
| LLM             | Google Gemini          |
| Embeddings      | `models/embedding-001` |
| Backend         | FastAPI                |
| Frontend        | Streamlit              |
| Vector Database | Qdrant                 |
| Database        | MongoDB                |




---

## ğŸ‘¨â€ğŸ’» Author

**Shisir Adhikari**

> RAG Chat System for Nepali Constitution Q&A
> [GitHub: shisir1729](https://github.com/shisir1729)

---
